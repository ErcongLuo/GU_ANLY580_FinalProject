{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project580Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErcongLuo/GU_ANLY580_FinalProject/blob/main/Project580Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLUFdgwwTbHD"
      },
      "source": [
        "# BERT Emotion Classification using COVID-19 Twitter Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXKShuDSTbHZ"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ3-fUlcTeIY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"TwitterSentimentDataset2.csv\", engine = \"python\" )\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRGpXsbU2BXa"
      },
      "source": [
        "df['emote'] = pd.factorize( df.emotion )[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6NT3Fd03ni9"
      },
      "source": [
        "df.emotion.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5p81bS_3dHR"
      },
      "source": [
        "df.emote.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo2oJEBydz6T"
      },
      "source": [
        "tweets = df['full_text'].tolist()\n",
        "tweets[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh49-Xs7_V4t"
      },
      "source": [
        "tweets[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxRUHdU2_G4e"
      },
      "source": [
        "tweets[30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPdLof2-f_ZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19z5rZEagBBw"
      },
      "source": [
        "### Cleaning Subroutine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOLNMEGuKgI6"
      },
      "source": [
        "clean = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpHJ0KLMWzbc"
      },
      "source": [
        "import re\n",
        "if clean:\n",
        "  for i in range (len(tweets)):\n",
        "      tweets[i] = re.sub(\"@[\\S]+\", \" \", tweets[i]) #remove all users\n",
        "      tweets[i] = re.sub(\"\\w+:\\/\\/\\S+\", \" \", tweets[i]) #remove all links\n",
        "  df.full_text = tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyIiNXW5_icw"
      },
      "source": [
        "tweets[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdfp8IG0_nKY"
      },
      "source": [
        "tweets[30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc5AX4vhgGmB"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATxX1nZwT6gI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, random_state = 42, train_size= 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MDeldGmVolp"
      },
      "source": [
        "df_train.emotion.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yDanOB0gKcb"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skl-cheGVZOW"
      },
      "source": [
        "!pip install datasets\n",
        "!pip install -q transformers torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU0ogJe5sG3d"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuU6EuMhTbHj"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 6\n",
        "lr_init = 5e-5\n",
        "max_len = 400 #updated in cell below\n",
        "warmup_steps = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIoSkJV0TbHj"
      },
      "source": [
        "### Batched Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3lKXjp1b0UL"
      },
      "source": [
        "from transformers import DistilBertTokenizer, BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every tweet\n",
        "for sent in df.full_text.to_list():\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)  # Tokenize\n",
        "    max_len = max(max_len, len(input_ids))    #update max length\n",
        "\n",
        "print('Max token length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9s_MsLcg-2x"
      },
      "source": [
        "\n",
        "def batch_data(data, bsize):\n",
        "    batches = []\n",
        "    sentences = data['full_text'].tolist()\n",
        "    labels = data['emote'].tolist()\n",
        "    for i in range(0, len(sentences), bsize):\n",
        "        s = sentences[i: i + bsize]\n",
        "        Y = labels[i: i + bsize]\n",
        "        X = tokenizer.batch_encode_plus(\n",
        "            s, max_length=max_len, padding='longest', truncation=True,\n",
        "            return_attention_mask=True, return_token_type_ids=False)\n",
        "        batches.append((X, Y, s))\n",
        "    return batches\n",
        "\n",
        "train_batches = batch_data(df_train, bsize=batch_size)\n",
        "test_batches = batch_data(df_test, bsize=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faCEx3mdW6X2"
      },
      "source": [
        "train_batches[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TltmIKM3TbHk"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBWQH1YgMjs3"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, DistilBertForSequenceClassification, \\\n",
        "  AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    #'bert-base-uncased',\n",
        "    num_labels=5,\n",
        "    output_hidden_states=True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0') # GPU\n",
        "    print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device('cpu') # CPU\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=lr_init)\n",
        "lr = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, \n",
        "    num_training_steps=len(train_batches))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j206-cgaTbHl"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8UWYcPdTbHm"
      },
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "def runner(batches, desc: str, train=True):\n",
        "    \n",
        "    grad_mode = torch.enable_grad if train else torch.no_grad\n",
        "    preds = []\n",
        "    \n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    \n",
        "    for epoch in range(epochs if train else 1):\n",
        "        \n",
        "        acc = load_metric(\"accuracy\", keep_in_memory=True)\n",
        "        f1 = load_metric(\"f1\", keep_in_memory=True)\n",
        "        cumloss = 0.0\n",
        "        embeds = []\n",
        "        \n",
        "        with tqdm(total=len(batches)) as bar:\n",
        "\n",
        "            for i, batch in enumerate(batches):\n",
        "                X, Y, _ = batch\n",
        "                inputs = torch.tensor(X['input_ids'], device=device)\n",
        "                attmsk = torch.tensor(X['attention_mask'], device=device)\n",
        "                labels = torch.tensor(Y, device=device)\n",
        "                batch = {'input_ids': inputs,\n",
        "                         'attention_mask': attmsk,\n",
        "                         'labels': labels}\n",
        "                with grad_mode():\n",
        "                    outputs = model(**batch)\n",
        "                    embeds.append(outputs[-1][1][:, 0, :].squeeze().detach().cpu())\n",
        "                    loss = outputs.loss\n",
        "                    if train:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        lr.step()\n",
        "                        optimizer.zero_grad()\n",
        "                    logits = outputs.logits\n",
        "                    Yhat = torch.argmax(logits, dim=-1)\n",
        "                    preds.append(Yhat)\n",
        "                    cumloss += loss.clone().detach().cpu().item()\n",
        "                    acc.add_batch(predictions=Yhat, references=Y)\n",
        "                    f1.add_batch(predictions=Yhat, references=Y)\n",
        "\n",
        "                bar.update(1)\n",
        "            bar.set_description('epoch: %s, %s loss: %.5f, f1-score: %.5f, accuracy: %.5f' %\n",
        "                                (epoch + 1, desc,\n",
        "                                 cumloss / (i + 1),\n",
        "                                 f1.compute(average=\"macro\")['f1'],\n",
        "                                 acc.compute()['accuracy']))\n",
        "                \n",
        "    embeds = torch.cat(embeds, dim=0)\n",
        "        \n",
        "    return preds, embeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZFo7acOcMkV"
      },
      "source": [
        "# Train model\n",
        "runner(train_batches, 'train');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdD2AUqJTbHn"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16sTsM5GOvji"
      },
      "source": [
        "# Evaluate training set\n",
        "preds, embeds = runner(train_batches, 'train', train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k_VKcj7LqdH"
      },
      "source": [
        "### Define Confusion Matrix Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J14NXBWIJ-EY"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def conf_mat(tensor_preds, batches):  \n",
        "  preds = torch.cat(tensor_preds).tolist()\n",
        "  y_true = []\n",
        "  for i, batch in enumerate(batches):\n",
        "      X, Y, _ = batch\n",
        "      y_true.extend(Y)\n",
        "  return(confusion_matrix(y_true, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xkqc-0CNlLW"
      },
      "source": [
        "conf_mat(preds, train_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMHr99DreMUJ"
      },
      "source": [
        "# Evaluate test set\n",
        "preds, embeds = runner(test_batches, 'test', train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwcWJJ3LTbHn"
      },
      "source": [
        "conf_mat(preds, test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l5nUfzaLzvh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4ifiwE8L0EZ"
      },
      "source": [
        "### Save Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4qMW_HS2P3D"
      },
      "source": [
        "model.save_pretrained(\"model/BERT1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcosGJjITbHp"
      },
      "source": [
        "### Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKbL6Gv2AhwD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"validation_set.csv\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7ngxwkeAnXC"
      },
      "source": [
        "df['full_text'] = df.text\n",
        "df['emote'] = df.LabelJasmine\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC4_t5EzAqNV"
      },
      "source": [
        "validation_batches = batch_data(df, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o5TvC0pH-gh"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained('.' ,num_labels = 5)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0') # GPU\n",
        "    print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device('cpu') # CPU\n",
        "\n",
        "model.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fud3kNdLHe-0"
      },
      "source": [
        "# Evaluate validation set\n",
        "preds, embeds = runner(validation_batches, 'validation', train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fZdq9akHmg3"
      },
      "source": [
        "conf_mat(preds, validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}